{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    3.7.5                         \n",
      "Location         C:\\Users\\Haingo\\AppData\\Roaming\\Python\\Python311\\site-packages\\spacy\n",
      "Platform         Windows-10-10.0.22631-SP0     \n",
      "Python version   3.11.7                        \n",
      "Pipelines        en_core_web_sm (3.7.1), en_core_web_lg (3.7.1), en_core_web_md (3.7.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if spacy is installed, and what models are available\n",
    "!python -m spacy info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy is a popular open-source library used for natural language processing (NLP) tasks. It provides efficient and accurate tokenization, part-of-speech tagging, named entity recognition, and other NLP functionalities.\n",
    "\n",
    "DocBin is a class provided by SpaCy that allows for efficient serialization and deserialization of SpaCy Doc objects. It is used to store and load large collections of documents in a binary format, which can be useful for training and processing large datasets.\n",
    "\n",
    "tqdm is a Python library that provides a progress bar for iterating over iterable objects. It is used to visualize the progress of tasks such as iterating over training or validation data, making it easier to track the progress and estimate the remaining time for completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "db = DocBin() # create a DocBin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "import json\n",
    "f = open('./all_train_data.json')\n",
    "TRAIN_DATA = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation data\n",
    "import json\n",
    "f = open('./all_validation_data.json')\n",
    "VALIDATION_DATA = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 415/415 [00:00<00:00, 4909.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Converting the training data JSON file into .spacy (docbin) objects\n",
    "for text, annot in tqdm(TRAIN_DATA['annotations']): \n",
    "    doc = nlp.make_doc(text) \n",
    "    ents = []\n",
    "    # Loop through the entities in each annotation\n",
    "    for start, end, label in annot[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents \n",
    "    db.add(doc)\n",
    "\n",
    "db.to_disk(\"./training_data.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:00<00:00, 4388.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Converting the validation data into .spacy (docbin) objects\n",
    "for text, annot in tqdm(VALIDATION_DATA['annotations']): \n",
    "    doc = nlp.make_doc(text) \n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents \n",
    "    db.add(doc)\n",
    "\n",
    "db.to_disk(\"./validation_data.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# Extracting config file using spacy config widget\n",
    "! python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     50.21    0.00    0.00    0.00    0.00\n",
      "  2     200        108.38   1817.77   88.26   87.39   89.15    0.88\n",
      "  5     400         97.55    296.84   95.08   94.22   95.96    0.95\n",
      "  8     600         18.09     25.66   95.77   95.77   95.77    0.96\n",
      " 12     800         10.26      8.66   96.15   95.97   96.32    0.96\n",
      " 18    1000          5.04      2.03   96.43   96.16   96.69    0.96\n",
      " 24    1200          1.53      0.67   95.99   95.13   96.88    0.96\n",
      " 32    1400         64.96     22.67   95.97   95.62   96.32    0.96\n",
      " 41    1600        262.18     76.51   95.78   95.60   95.96    0.96\n",
      " 53    1800         33.62      7.82   95.88   95.61   96.14    0.96\n",
      " 67    2000         50.20     17.98   95.69   95.43   95.96    0.96\n",
      " 85    2200         93.46     16.95   95.76   95.94   95.59    0.96\n",
      "106    2400        122.69     23.38   95.89   95.28   96.51    0.96\n",
      "128    2600         61.88     13.50   95.99   95.29   96.69    0.96\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "model-last\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "! python -m spacy train config.cfg --output ./ --paths.train ./training_data.spacy --paths.dev ./validation_data.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous lines of code were used to create the model. It is saved under the folder model-best.\n",
    "\n",
    "The next line of codes are required in the chatbot implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the customer model saved in the model-best folder\n",
    "nlp_ner = spacy.load(\"./model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In the morning I eat oatmeal and clothes.<br>              For lunch I usually eat \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pasta\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pizza\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " and an elephant from my favorite italian restaurant.<br>              For dinner, I eat \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    greek sandwiches\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " with my collegues during the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    week days\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PREFERENCE</span>\n",
       "</mark>\n",
       ", and occasionally \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    burgers\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " during the weekend.<br>              During snack time, I usually have fruits, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    energy bars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SPECIALNEED</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    popcorn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add user input here\n",
    "doc = nlp_ner('''In the morning I eat oatmeal and clothes.\n",
    "              For lunch I usually eat pasta, pizza and an elephant from my favorite italian restaurant.\n",
    "              For dinner, I eat greek sandwiches with my collegues during the week days, and occasionally burgers during the weekend.\n",
    "              During snack time, I usually have fruits, energy bars, and popcorn.''')\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Milesone 2) \n",
    "In the previous model, the correctly predicted foods were:\n",
    "- oatmeal\n",
    "- pasta\n",
    "- pizza\n",
    "- greek sandwiches\n",
    "- burgers\n",
    "- fruits\n",
    "- energy bars\n",
    "- popcorn \n",
    "as food \n",
    "\n",
    "But it also, incorrectly predicts:\n",
    "- clothes\n",
    "- occasionally (burgers)\n",
    "\n",
    "#### (Milestone 3) \n",
    "In the current model, the correctly predicted foods are:\n",
    "- oatmeal\n",
    "-pasta\n",
    "- pizza\n",
    "- greek sandwich\n",
    "- burgers\n",
    "- bars\n",
    "\n",
    "But it also incorrectly predicts:\n",
    "- colleges during & during\n",
    "- week days\n",
    "- weekend\n",
    "- fruits\n",
    "- energy [bars]\n",
    "- popcorn\n",
    "\n",
    "#### (Milestone 4) \n",
    "The model correctly predicts:\n",
    "- pasta\n",
    "- pizza\n",
    "- greek sandwiches\n",
    "- burgers\n",
    "- popcorn\n",
    "\n",
    "but incorrectly predicts:\n",
    "- oatmeal\n",
    "- weekdays\n",
    "- fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pasta', 'pizza', 'greek sandwiches', 'burgers', 'popcorn']\n"
     ]
    }
   ],
   "source": [
    "# Return the food items from the sentence\n",
    "food_ner = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'FOOD':\n",
    "        food_ner.append(ent.text)\n",
    "\n",
    "print(food_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp_ner('''I am allergic to milk. I am pregnant and I want some ice cream.\n",
    "              I used to eat fish and bacon before following a vegetarian diet.''')\n",
    "spacy.displacy.render(doc1, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Milestone 3) \n",
    "In this piece of sentence, the model correctly predicts:\n",
    "- Allergic to milk (as a special need)\n",
    "- Pregnant (as a special need)\n",
    "- [some] ice cream (as food)\n",
    "- fish (as food)\n",
    "- bacon (as food)\n",
    "\n",
    "But incorrectly predicts:\n",
    "- Vegetarian (as food instead of preference)\n",
    "\n",
    "#### (Milestone 4) \n",
    "The model correctly classifies: \n",
    "- Allergic to milk (as a special need)\n",
    "- Pregnant (as a special need)\n",
    "- ice cream as food\n",
    "- fish (as food)\n",
    "- bacon [before] (as food)\n",
    "- vegetarian diet (as preference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp_ner('''I am on Keto diet. I eat a lot of meat, eggs, and cheese.\n",
    "               I am a body builder..''')\n",
    "spacy.displacy.render(doc2, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Milestone 3) \n",
    "The model correctly classifies: \n",
    "- meat (as food)\n",
    "- eggs (as food)\n",
    "- cheese (as food)\n",
    "- body builder (as preference)  as defined by the training data\n",
    "\n",
    "But it incorrectly classifies \n",
    "- Keto diet (as food instead of a preference)\n",
    "\n",
    "### (Milestone 4) \n",
    "The model correctly classifies:\n",
    "- Keto diet (as preference)\n",
    "- Body builder (as preference)\n",
    "\n",
    "But fails to classify:\n",
    "- meat, eggs and cheese (as food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">more meat, more \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cheese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " and more \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    eggs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FOOD</span>\n",
       "</mark>\n",
       " for us<br>               </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc2 = nlp_ner('''more meat, more cheese and more eggs for us\n",
    "               ''')\n",
    "spacy.displacy.render(doc2, style=\"ent\", jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
